---
marp: true
theme: mytheme
paginate: true 
---

<!-- _class: title -->

<h1> ベイズ推論による機械学習入門 </h1>
<div class="split"> </div>
<h2> ベイズ推論による学習と予測(3.1-3.2) </h2>

<p>
2022/5/11
情報理工学科 竹川修平
</p>

---

<!-- _class: mokuji -->
<h1> 目次 </h1>
<span> 第3章 ベイズ推論による学習と予測 (3.1-3.2) </span>
<div class="split"> </div>
<div>
    <ul>
        <li> 3.1 学習と予測 <span> 3 </span> </li> 
        <div class="split"> </div>
        <li> 3.2 離散確率分布の学習と予測 <span> 11 </span> </li>
    </ul>
</div>

---
<!-- header: 3.1 学習と予測 -->
<!-- _class: section_title -->
<h1> 3.1 学習と予測 </h1>

---
<!-- class: card -->

<h1> 学習と予測 </h1>
<ul>
    <li>
    一般的に機械学習の分野では, モデルの持つパラメータの値をデータから決定することを<b>学習 (training, learning)</b>という.
    </li>
    <li>
    ベイズ推論の枠組みでは, パラメータも不確実性を伴う確率変数として扱うので, 確率計算によってデータを観測した後のパラメータの事後分布を求めることが<b>学習</b>にあたる. 
    </li>
    <li>
    多くの場合では単純にパラメータを得るだけでなく, まだ観測されていない値に関する予測を行うことも主要な課題になる.  予測分布に関しても確率推論を使って求め, 未知の値に対する平均値やばらつき具合などの各種期待値を調べたり,  サンプルを得ることによって視覚的に予測を理解することが行われる. 
    </li>
</ul>



---
<!-- class: detals-->
<!-- header: 3.1.1 パラメータの事後分布-->
<h1>  パラメータの事後分布 </h1>
<ul>
<li>

$\mathcal{D}$: 訓練データの集合
<li>

$\theta$: モデルに含まれる未知のパラメータ
</li>
</li>
</ul>
<div class="card">

ベイズ学習では次のような同時分布$p(\mathcal{D},\theta)$を考えることでデータを表現するモデルを構築
$$p(\mathcal{D},\theta) = p(\mathcal{D}\vert\theta)p(\theta)$$
</div>
<ul>
<li>

パラメータに関する不確実性は事前分布$p(\theta)$を設定することで反映される.
</li>
<li>

$p(\mathcal{D}\vert\theta)$は特定のパラメータ$\theta$からどのように$\mathcal{D}$が発生したかを記述しており, これを$\theta$の関数とした場合は<b>尤度関数(likelihood function)</b>と呼ばれる.
</li>
</ul>

---
<div class="card">

データ$\mathcal{D}$を観測した後ではパラメータの不確実性は次のように更新される
$$ p(\theta\vert\mathcal D) = \frac{p(\mathcal D\vert\theta)p(\theta)}{p(\mathcal D)}$$
</div>
<ul>
<li>

この条件付き分布$p(\theta\vert\mathcal D)$を計算することがベイズ学習の枠組みでの「学習」にあたる
</li>
<li>

事後分布$p(\theta\vert\mathcal D)$は$p(\theta)$と比べて尤度関数 $p(\mathcal{D}\vert\theta)$ を通すことによって観測データ$\mathcal D$に関する特徴を捉えていることが期待できる
</li>
</ul>

---

<!-- header: 3.1.2 予測分布 -->
<h1> 3.1.2 予測分布 </h1>
<ul>
<li> 

$x_*$: 未観測のデータ
</li>
</ul>
<div class="card">

学習されたパラメータの分布を使って<b>予測分布(predivtive distribution)</b>を計算することによって未観測データ$x_*$に関する知見を得られる.
$$p(x_*\vert\mathcal D) = \int p(x_*\vert\theta)p(\theta\vert\mathcal D)d\theta $$
</div>

<ul>
<li>

$p(\theta\vert\mathcal D)$で様々な$\theta$について重み付けして$p(x_*\vert\mathcal D)$を平均化
</li>
</ul>
<div class="tips">
</div>

---

<div class="img_center">
<img src="graphicalmodel.png" width="400">
</div>

<ul>
<li>

上のモデルではデータ$\mathcal D$も未観測値$x_*$もパラメータ$\theta$に発生過程が支配されているが, $\mathcal D$と$x_*$には直接的な依存関係は仮定おらず, パラメータが与えられたもとで条件付き独立であるといえる. 
このような仮定を置くとき, 観測データは i.i.d.(independent and identically distributed)であるという.

</li>
</ul>

---

このような仮定において, 同時分布は次のようになる
$$p(\mathcal D,x_*,\theta) = p(\mathcal D\vert\theta)p(x_*\vert\theta)p(\theta)$$
データ$\mathcal D$が手元にあるとすれば, 残りの変数の事後分布は

$$
\begin{aligned}
p(x_*, \theta\vert\mathcal D)&=\frac{p(\mathcal D, x_\ast, \theta)}{p(\mathcal D)}　\\
&=\frac{p(\mathcal D\vert\theta)p(x_*\vert\theta)p(\theta)}{p(\mathcal D)} \\ 
&=p(x*\vert\theta)p(\theta\vert\mathcal D)
\end{aligned}
$$
<ul>
<li>

上の式を, 周辺化によって$\theta$を除去すれば予測分布が得られる.
</li>
</ul>
<div class="card">

データ$\mathcal D$を観測していない状態で予測分布を求めても良い. 
$$p(x_*) = \int p(x_*\vert\theta)p(\theta)d\theta $$ 
</div>


---

<ul>
<li>

この場合は事前知識$p(\theta)$だけに頼っているので非常に大雑把な予測である. 
</li>
</ul>
<div class="card">

データ$\mathcal D$と未観測値$x_\ast$が条件付き独立なモデルにおいて, 未観測値$x_\ast$を予測するには,
まず, $\mathcal D$を用いてパラメータの事後分布を学習し, その時点で$\mathcal D$は捨て, 得られた事後分布を周辺化することによって予測分布を求める.
</div>

<ul>
<li>

データ$\mathcal D$の情報を全て事後分布$p(\mathcal D\vert\theta)$に押し込めるのは計算上非常に便利だが, データ量が変化しても, モデルの表現能力は変化しないという制限がある.
</li>
<li>

データ$\mathcal D$に合わせて予測モデルの表現能力を柔軟に変える確率モデルとして<b>ガウス過程(Gaussian process)</b>や<b>ベイジアンノンパラメトリクス(Bayesian nonparametrics)</b>がある. 
</li>

---

<!-- header: 3.1.3 共役事前分布-->
<!-- _class: section_title -->
# 3.1.3 共役事前分布

---
<!-- class: details -->
<h1> 共役事前分布</h1>

<div class="card_with_title">
<p>
共役事前分布(conjugate prior)
</p>

事前分布$p(\theta)$と事後分布$p(\theta\vert\mathcal D)$が同じ種類の確率分布を持つように設定された事前分布.
</div>
<ul>
<li>

どのような事前分布が共役になりうるかは尤度関数$p(\theta\vert\mathcal D)$の設計による
</li>

<li>
ガウス分布のようにパラメータを二つもつような分布では, どのパラメータを学習させたいかによって共役事前分布が異なる. 
</li>
</ul>

---

<h1> 共役事前分布を使う利点 </h1>
<b>事後分布や予測分布の計算が簡単かつ効率的にできる.</b>

<div class="card">

データセット$\mathcal D_1$を観測したあとの事後分布は次のようになる.
$$p(\theta\vert\mathcal D_1)\propto p(\mathcal D_1\vert\theta)p(\theta)$$
さらに新規データセット$\mathcal D_2$を観測した場合の事後分布は次のようになる.
$$p(\theta\vert\mathcal D_1, \mathcal D_2)\propto p(\mathcal D_2\vert\theta)p(\theta\vert\mathcal D_1)$$
</div>
<ul>
<li>

上式のようにデータセットを小分けにして逐次的に学習する場合, 共役事前分布を用いれば$p(\theta)$, $p(\mathcal D_1\vert\theta)$, $p(\mathcal D_2\vert\theta)$が全て同じ形式になりプログラムによる実装がシンプルになる.
</li>
<li>
解析的に事後分布を求めることができない複雑な拡張モデルにおいて, 共役な分布を部分的に組み合わせるて全体のモデルの構築をすることで計算効率の高い近似アルゴリズを導ける(4章以降).

---
<style>
    table, th, td{
        font-size: 75%;
    }
    </style>
|尤度関数|パラメータ|共役事前分布|予測分布
|:----:|:----:|:----:|:----:|
|ベルヌーイ分布|$\mu$|ベータ分布|ベルヌーイ分布|
|二項分布|$\mu$|ベータ分布|ベータ・二項分布|
|カテゴリ分布|$\bm{\pi}$|ディリクレ分布|カテゴリ分布|
|多項分布|$\bm{\pi}$|ディリクレ分布|ディリクレ・多項分布|
|ポアソン分布|$\lambda$|ガンマ分布|負の二項分布|
|1次元ガウス分布|$\mu$|1次元ガウス分布|1次元ガウス分布|
|1次元ガウス分布|$\lambda$|ガンマ分布|1次元ステューデントのt分布|
|1次元ガウス分布|$\mu, \lambda$|ガウス・ガンマ分布|1次元ステューデントのt分布|
|多次元ガウス分布|$\bm{\mu}$|多次元ガウス分布|多次元ガウス分布|
|多次元ガウス分布|$\bm{\Lambda}$|ウィシャート分布|1次元ステューデントのt分布|
|多次元ガウス分布|$\bm{\mu},\bm{\Lambda}$|ガウス・ウィシャート分布|1次元ステューデントのt分布|

<li> 
<b>負の二項分布(negative binominal distribution)</b>や<b>スチューデントのt分布(student's t distribution)</b>は以降の予測分布の計算で登場する.
</li>

---

<!-- header: 3.1.4 共役でない事後分布の利用 -->
# 共役でない事後分布の利用
<ul>
<li>
尤度関数に対応する共役事前分布をそのまま使うとデータに関する興味深い構造をうまく捉えられないケースがある. そのような場合は共役でない事前分布を使うこともある.
</li>
<li>
例としてガウス分布の平均パラメータに対して共役でないガンマ分布を過程すると事前分布はガンマ分布にならない. このような場合<b>MCMC(Markov chain Monte Carlo)</b>や<b>変分推論(variational inference)</b>を使うアイデアがある.
</li>
</ul>
<div class="card_with_title">
<p>
変分推論
</p>

$\eta$:変分パラメータ(variational parameter)を使った分布$q(\theta;\eta)$で事後分布$p(\theta\vert\mathcal D)$を近似的に表現できると仮定し, 以下の最小化問題を解く.
$$\eta_{opt} =\underset{\eta}{\text{argmin}}\text{KL}[q(\theta;\eta)\vert\vert p(\theta|\mathcal D)]$$
</div>

---
<ul>
<li>
通常この最小化問題は解析的に解くことができないので, <b>勾配法(gradient method)</b>などの最適化アルゴリズムを使う.
</li>
<li>
共役事前分布を使った解析的な計算と比べて, 最適化のための計算コストが余分にかかる.
<li>

得られた近似分布$q(\theta;\eta_{opt})$がどれだけ事後分布を近似できているかは一般的には把握できない. 
ただし, 複数の近似分布の仮定{$q(\theta;\eta_1),...,q(\theta;\eta_K)$}でどれが最もよいかは<b>ELBO(evidence lower bound)</b>という値を使って定量的に評価できる.

---

<!-- _class: section_title -->
<!-- header: 3.2.1 ベルヌーイ分布の学習と予測-->

<h1> 3.2.1 ベルヌーイ分布の学習と予測</h1>

---
<!-- class: details -->
<h1>ベルヌーイ分布の学習と予測 </h1>

<div class="card">

$x\in\{0,1\}$上の確率分布であるベルヌーイ分布のパラメータ$\mu$の分布の推論を考える.
$$p(x\vert\mu)=\text{Bern}(x\vert\mu)\coloneqq\mu^x(1-\mu)^{1-x}$$
ベルヌーイ分布のパラメータの要件$\mu\in(0,1)$を満たす値を生成してくれるベータ分布を事前分布として採用する.
$$p(\mu)=\text{Beta}(\mu\vert a,b)\coloneqq C_B(a,b)\mu^{1-a}(1-\mu)^{1-b}$$
</div>
<ul>
<li>

ここで$a,b$は事前分布$p(\mu)$をコントロールするためにパラメータになっている. $\mu$自体がパラメータなので$a,b$をパタメータのためのパラメータということで<b>超パラメータ(hyper-parameter)</b>と呼ばれる.
</li>
<li>
今回のモデルでは超パラメータの学習は行わず, 既知の値として与えられているとする.
</li>

---

事後分布を実際に計算してみる.
<ul>
<li>

$\bm{X}=\{x_1, ..., x_N\}$: $N$個のデータ点

$$
\begin{aligned}
p(\mu\vert\bm X)&=\frac{p(\bm X\vert\mu)p(\mu)}{p(\bm X)} \\ 
&= \frac{\{\prod_{n=1}^{N}p(x_n\vert\mu)\}p(\mu)}{p(\bm X)}\\
&\propto\{\prod_{n=1}^{N}p(x_n\vert\mu)\}p(\mu)\\
\end{aligned}
$$
ここで対数をとる
$$
\begin{aligned} 
\text{ln}p(\mu\vert\bm X)&=\sum_{n=1}^{N}\text{ln}(x_n\vert\mu)+\text{ln}p(\mu)+\text{const.}\\
\end{aligned}
$$

---
$$\begin{aligned}
&=\sum_{n=1}^{N}x_n\text{ln}\mu+\sum_{n=1}^{N}(1-x_n)\text{ln}(1-\mu)\\
    &\quad+(a-1)\text{ln}\mu+(b-1)\text{ln}(1-\mu)+\text{const.}\\
    &=(\sum_{n=1}^{N}x_n+a-1)\text{ln}\mu+(N-\sum_{n=1}^{N}x_n+b-1)\text{ln}(1-\mu)+\text{const.}
\end{aligned}$$
<div class="ref">
<p><参考>ベータ分布(対数) </p>

$$\text{lnBeta}(\mu\vert a,b)=(a-1)\text{ln}(\mu)+(b-1)\text{ln}(1-\mu)+\text{ln}C_B(a,b)$$
</div>
<div class="card">
事後分布は以下のようになる.

$$\hat a=\sum_{n=1}^{N}x_n+a, \hat b=N-\sum_{n=1}^{N}x_n+b$$
$$ p(\mu\vert\bm X) = \text{Beta}(\mu\vert\hat a,\hat b)$$
</div>

---

+ 事後分布が事前分布と同じ形式(ベータ分布)となった.
+ $\hat a$は$a$に$x=1$となる回数が追加され, $\hat b$は$b$に$x=0$となる回数が追加されている. コインで例えると, ベータ分布は今までに表と裏が何回ずつ出たかを記憶する役割を果たしている.

<div class="ref2">
<b>(参考) 経験ベイズ法</b>

3.2.1節では事後分布を求めた. この際パラメータ$\hat a, \hat b$を求めたが, これは事前分布のパラメータ$a,b$自体を更新したわけではない.$a,b$などの超パラメータ自体を観測データに合わせて直接調整する方法も存在し, これは<b>経験ベイズ法(empirical Bayes)</b>と呼ばれている.確率推論によって導かれる手法ではないため, 厳密にはベイズ手法ではない.
ベイズ学習の枠組みでは, 事前分布の超パラメータはドメイン知識を反映した上で固定値として設定するものである. 超パラメータの値もデータから学習したい場合, 超パラメータの対する事前分布を用意すれば完全なベイズの枠組みとして学習させることもできる.
</div>

---

未観測の値$x_\ast\in\{0,1\}$に対する予測分布を計算する. 後に事後分布を使った予測分布を求めるが, 便宜上, まずは事前分布$p(\mu)$を使った予測分布を計算する.

$$\begin{aligned}
p(x_\ast)&=\int p(x_\ast\vert\mu)p(\mu)\text{d}\mu \\
&=\int \text{Bern}(x_\ast\vert\mu)\text{Beta}(\mu\vert a,b)\text{d}\mu \\
&=C_B(a,b)\int\mu^{x_\ast}(1-\mu)^{1-x_\ast}\mu^{a-1}(1-\mu)^{b-1}\text{d}\mu\\
&=C_B(a,b)\int\mu^{x_\ast+a-1}(1-\mu)^{1-x_\ast+b-1}\text{d}\mu \\
&=\frac{C_B(a,b)}{C_B(x_\ast+a,1-x_\ast+b)}\\
&=\frac{\Gamma(a+b)\Gamma(x_\ast+a)\Gamma(1-x_\ast+b)}{\Gamma(a)\Gamma(b)\Gamma(a+b+1)}
\end{aligned}$$

<div class="ref" style="text-align:right">

(参考)ベータ分布の正規化項 $C_B(a,b)\coloneqq \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}$ 
</div>

---
$$\begin{aligned}
p(x_\ast=1)&=\frac{\Gamma(a+b)\Gamma(1+a)\Gamma(b)}{\Gamma(a)\Gamma(b)\Gamma(a+b+1)}\\
&=\frac{a}{a+b} \\
p(x_\ast=0)&=\frac{\Gamma(a+b)\Gamma(a)\Gamma(1+b)}{\Gamma(a)\Gamma(b)\Gamma(a+b+1)} \\
&=\frac{b}{a+b}
\end{aligned}$$
<div class="card">

予測分布は以下のようになる.
$$p(x_\ast)=(\frac{a}{a+b})^{x_\ast} (\frac{b}{a+b})^{1-x_\ast}=\text{Bern}(x_\ast\vert\frac{a}{a+b})$$
</div>

+ 例えば, $a=1, b=1$とすると,$\langle{x_\ast}\rangle_{p(x_\ast)} = 0.5$

---

次に事後分布を用いた予測分布を計算する.
+ 事後分布$p(\mu\vert\bm X)$もベータ分布であるため$p(x_\ast\vert\bm X)$は超パラメータ$a,b$をそれぞれ$\hat a,\hat b$に変えるだけで求められる. 
<div class="card">

$$\begin{aligned}p(x_\ast)&=\int \text{Bern}(x_\ast\vert\mu)\text{Beta}(\mu\vert a,b)\text{d}\mu\\
p(x_\ast\vert\bm X)&=\int \text{Bern}(x_\ast\vert\mu)\text{Beta}(\mu\vert \hat a,\hat b)\text{d}\mu\\
&=\text{Bern}(x_\ast\vert\frac{\hat a}{\hat a+\hat b})\\
&=\text{Bern}(x_\ast\vert\frac{\sum_{n=1}^N a}{N + a+ b})
\end{aligned}$$
</div>

---
<!-- header: 3.2.2 カテゴリ分布の学習と予測 --->
# 3.2.2 カテゴリ分布の学習と予測

<div class="card">

$K$値をとるカテゴリ分布のパラメータ学習を考える.

$$p(\bm s\vert\bm \pi)=\text{Cat}(\bm s\vert \bm \pi)\coloneqq\prod_{k=1}^K\pi_k^{s_k}$$
$$(s_k\in\{0,1\},\sum_{k=1}^Ks_k=1, \pi_k\in(0,1),\sum_{k=1}^K\pi_k=1)$$
パラメータの要件を満たす$K$次元の変数を生成してくれるディリクレ分布を事前分布として採用
$$p(\bm \pi)=\text{Dir}(\bm \pi\vert\bm \alpha)\coloneqq C_D(\bm \alpha)\prod_{k=1}^K\pi_k^{\alpha_k-1}$$
$$(\bm \alpha\in{\R^+}^K)$$

---
先程と同様にディリクレ分布がカテゴリ分布に対する共役事前分であることを確かめる.

+ N個の離散値データ$\bm S=\{\bm s_1, ..., \bm s_N\}$が手元にあるとする.
$$\begin{aligned}
p(\bm \pi\vert\bm S)&\propto p(\bm S\vert\bm \pi)p(\bm \pi)\\
&=\{\prod_{n=1}^N\text{Cat}(\bm s_n\vert \bm \pi)\}\text{Dir}(\bm \pi\vert\bm \alpha)
\end{aligned}$$
対数をとる.
$$\begin{aligned}
\ln p(\bm \pi\vert\bm S)&=\sum_{n=1}^N\ln\text{Cat}(\bm s_n\vert\pi)+\ln\text{Dir}(\bm \pi\vert\bm \alpha)+\text{const.}\\
&=\sum_{n=1}^N\sum_{k=1}^Ks_{n,k}\ln\pi_k+\sum_{k=1}^K(\alpha_k-1)\ln\pi_k + \text{const.}\\
&=\sum_{k=1}^K(\sum_{n=1}^Ns_{n,k}+\alpha_k-1)\ln\pi_k+\text{const.}
\end{aligned}$$

---

<div class="ref">

(参考)ディリクレ分布(対数)
$$\ln Dir(\bm \pi\vert\bm\alpha)=\sum_{k=1}^K(\alpha_k-1)\ln\pi_k + \ln C_D(\bm \alpha)$$
</div>
<div class="card">
事後分布は以下のようになる.

$$\hat\alpha_k=\sum_{n=1}^Ns_{n,k}+\alpha_k  \text{ for }k=1,...,K$$
$$p(\bm \pi\vert\bm S)=\text{Dir}(\bm\pi\vert\hat{\bm\alpha})$$
</div>

次に未観測値$\bm s_\ast$の予測分布の計算を行う.
$$\begin{aligned}
p(\bm s_\ast)&=\int p(\bm s_\ast\vert\bm \pi)p(\pi)\text{d}\bm\pi
=\int \text{Cat}(\bm s_\ast\vert\bm \pi)\text{Dir}(\pi)\text{d}\bm\pi\\
&=C_D(\bm \alpha)\int \prod_{k=1}^K\pi_k^{s_{\ast,k}}\pi_k^{\alpha_k-1}\text{d}\bm\pi

\end{aligned}$$

---

$$\begin{aligned}
&=C_D(\alpha)\int \prod_{k=1}^K\pi_k^{s_{\ast,k}+\alpha_k-1}\text{d}\bm\pi \\
&=\frac{C_D(\alpha)}{C_D((s_{_\ast,k+\alpha_k})_{k=1}^K)}
\end{aligned}$$

<div class="ref">
(参考)ディリクレ分布の正規化項

$$C_D(\bm\alpha)=\frac{\Gamma(\sum_{k=1}^K\alpha_k)}{\prod_{k=1}^K\Gamma(\alpha_k)}$$
</div>

$$p(\bm s_\ast)=\frac{\Gamma(\Sigma_{k=1}^K\alpha_k)\prod_{k=1}^K\Gamma(s_{\ast,k}+\alpha_k)}{\prod_{k=1}^K\Gamma(\alpha_k)\Gamma(\sum_{k=1}^K(s_{\ast,k}+\alpha_k))}$$
$s_{\ast,k'}=1$となる場合を計算すると
$$p(s_{\ast,k'}=1)=\frac{\alpha_{k'}}{\sum_{k=1}^K\alpha_k}$$

---
<div class="card">

予測分布は以下のようになる.
$$p(s_\ast)=\text{Cat}(s_\ast\vert(\frac{\alpha_{k}}{\sum_{i=1}^K\alpha_i})_{k=1}^K)$$
事後分布を用いた予測分布は超パラメータを$\hat {\bm\alpha}$に置き換えれば以下のようになる.
$$p(s_\ast\vert\bm S)=\text{Cat}(s_\ast\vert(\frac{\sum_{n=1}^Ns_{n,k}+\alpha_{k}}{N+\sum_{i=1}^K\alpha_i})_{k=1}^K)$$